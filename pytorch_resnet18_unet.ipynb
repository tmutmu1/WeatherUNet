{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 256, 256, 3)\n",
      "0 255\n",
      "(2, 6, 256, 256)\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(256, 256, count=2)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "#target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask\n",
    "#helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Images...\n",
      "Appending Images...\n",
      "Input:  (1250, 256, 256, 3)\n",
      "Masks:  (1250, 3, 256, 256)\n",
      "Reading Images...\n",
      "Appending Images...\n",
      "Input:  (125, 256, 256, 3)\n",
      "Masks:  (125, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 1250, 'val': 125}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import cv2\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.numImageInput = 3\n",
    "        self.count = count\n",
    "        #self.input_images, self.target_masks = simulation.generate_random_data(256, 256, count=count)      \n",
    "        #self.input_images, self.target_masks = self.get_images(3,3, count)\n",
    "        self.get_images(3,3, count)\n",
    "        \n",
    "        #print(self.target_masks)\n",
    "        #self.target_masks = np.reshape(self.target_masks, (count, 255, 255))\n",
    "        print(\"Input: \", self.input_images.shape)\n",
    "        print(\"Masks: \", self.target_masks.shape)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        #print(\"Image: \"+str(image.shape))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]\n",
    "\n",
    "    def get_images(self,X,Y, count):\n",
    "        count+=self.numImageInput\n",
    "        path = \"/home/ubuntuos/WeatherTileExamples/scripts/output/cropped/\" + \"(\"+str(X)+\", \" + str(Y) +\")/\"\n",
    "   \n",
    "        files= os.listdir(path)\n",
    "        images = []\n",
    "        image_output = []\n",
    "        #output = []\n",
    "       \n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith(\"(\"+str(X)+\", \"+str(Y)+\").png\"):\n",
    "                images.append(file)\n",
    "        #images = np.random.choice(np.array(images), count, replace=False)\n",
    "        #print(np.random.choice(list(enumerate(np.array(images)[:count]))))\n",
    "        \n",
    "        images.sort()\n",
    "        #rand_number = random.randint(0, len(images)-count)\n",
    "        #images = images[rand_number:rand_number+count]\n",
    "        \n",
    "        rand_int = np.random.choice(len(images)-self.numImageInput, size=count, replace=False)\n",
    "        \n",
    "        print(\"Reading Images...\")\n",
    "        #for image_path in images:\n",
    "        for i in range(len(images)):\n",
    "            if (i in rand_int or i-1 in rand_int or i-2 in rand_int or i-self.numImageInput in rand_int):\n",
    "                #input_path = os.path.join(path, image_path)\n",
    "                input_path = os.path.join(path, images[i])\n",
    "                an_image = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image_output.append(np.array(an_image))\n",
    "            else:\n",
    "                image_output.append(0)\n",
    "        output_mask = []\n",
    "        output = []\n",
    "        \n",
    "        \n",
    "        #print(rand_int)\n",
    "        print(\"Appending Images...\")\n",
    "        for i in range(count-self.numImageInput):\n",
    "            #mask_temp = np.dstack((image_output[i+3]))\n",
    "            mask_temp = [(np.round(image_output[rand_int[i]+self.numImageInput]/255*3)/3).astype(\"float16\"),\n",
    "                         (np.round(image_output[rand_int[i+1]+self.numImageInput]/255*3)/3).astype(\"float16\"),\n",
    "                         (np.round(image_output[rand_int[i+2]+self.numImageInput]/255*3)/3).astype(\"float16\")]\n",
    "    \n",
    "\n",
    "            #print(rand_int[i])\n",
    "            image_temp = np.dstack((image_output[rand_int[i]], image_output[rand_int[i]+1],image_output[rand_int[i]+2]))\n",
    "\n",
    "            #image_temp = np.array([image_output[i], image_output[i+1],image_output[i+2]])\n",
    "            output.append(image_temp)\n",
    "            output_mask.append(mask_temp)\n",
    "        self.input_images = np.array(output)\n",
    "        #self.target_masks = np.divide(np.array(output_mask), 255)\n",
    "        #self.target_masks = np.floor((np.array(output_mask)*4.0) / 255)/4\n",
    "        #self.target_masks = np.rint(np.array(output_mask)*3.0 / 255) /3\n",
    "        self.target_masks = np.array(output_mask)\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(1250, transform=trans)\n",
    "#train_set = SimDataset(1000, transform=trans)\n",
    "val_set = SimDataset(125, transform=trans)\n",
    "#val_set = SimDataset(100, transform=trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "#batch_size = 25\n",
    "#batch_size = 20\n",
    "batch_size = 3\n",
    "#batch_size = 1\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 256, 256]) torch.Size([3, 3, 256, 256])\n",
      "-2.117904 1.3081232 -1.7592723 0.56345356\n",
      "0.0 0.6665 0.04385 0.1184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f310ef9a5c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "#inputs = next(iter(dataloaders['train']))\n",
    "\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "base_model = models.resnet18(pretrained=False)\n",
    "    \n",
    "list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-11           [-1, 64, 64, 64]               0\n",
      "           Conv2d-12           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 64, 64]             128\n",
      "             ReLU-14           [-1, 64, 64, 64]               0\n",
      "           Conv2d-15           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 64, 64]             128\n",
      "             ReLU-17           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-18           [-1, 64, 64, 64]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
      "           Conv2d-24          [-1, 128, 32, 32]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 32, 32]             256\n",
      "             ReLU-26          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
      "             ReLU-30          [-1, 128, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-34          [-1, 128, 32, 32]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 82.01\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 127.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "#summary(base_model, input_size=(3, 224, 224))\n",
    "summary(base_model, input_size=(inputs[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import resnet18 #added\n",
    "\n",
    "\n",
    "def createUpLayer(in_channels, out_channels, kernel, padding):\n",
    "    \"\"\"return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\"\"\"\n",
    "    \"\"\"return nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "    )\"\"\"\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel, padding=padding)\n",
    "    )\n",
    "\n",
    "def createDownLayer(size): #added\n",
    "        return(nn.Sequential(\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Conv2d(size, size*2, 3, stride = 2, padding=1),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) #not in Google's model\n",
    "        ))\n",
    "        \"\"\"return(nn.Sequential(\n",
    "            resnet18.BasicBlock(size, size*2, stride = 2, downsample = nn.Sequential(\n",
    "                    nn.Conv2d(size, size*2, 3, stride = 2, padding=1),\n",
    "                    nn.BatchNorm2d(size*2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
    "                )),\n",
    "            resnet18.BasicBlock(size*2, size*2, stride = 1)))\"\"\"\n",
    "        \n",
    "def createBasicLayer(inputSize, size): #added\n",
    "        return(nn.Sequential(\n",
    "            nn.Conv2d(inputSize, size, 3, stride = 2, padding=1),\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Conv2d(size, size, 3, stride = 2, padding=1)\n",
    "        ))\n",
    "\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())       \n",
    "   \n",
    "        \n",
    "        self.layer0 = createBasicLayer(3, 64)\n",
    "        self.layer1 = createDownLayer(64)  # size=(N, 128, x.H/8, x.W/8) # changed\n",
    "        self.layer2 = createDownLayer(128)  # size=(N, 256, x.H/16, x.W/16)  # changed      \n",
    "        self.layer3 = createDownLayer(256)  # size=(N, 512, x.H/32, x.W/32)  # changed\n",
    "        \n",
    "        self.layer4 = createDownLayer(512) # added\n",
    "        self.layer5 = createDownLayer(1024) # added\n",
    "        #self.layer6 = createDownLayer(2048) # added\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        \n",
    "        #self.conv_up5 = createUpLayer(4096 + 2048, 2048, 3, 1) # added\n",
    "        self.conv_up4 = createUpLayer(2048 + 1024, 1024, 3, 1) # added\n",
    "        \n",
    "        self.conv_up3 = createUpLayer(1024 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = createUpLayer(512 + 256, 256, 3, 1)\n",
    "        self.conv_up1 = createUpLayer(256 + 128, 128, 3, 1)\n",
    "        self.conv_up0 = createUpLayer(128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_original_size = createBasicLayer(192, 64)\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\"\"\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        layer0 = self.layer0(input)    \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer5 = self.layer5(layer4) #added        \n",
    "        #layer6 = self.layer6(layer5) #added        \n",
    "\n",
    "        #print(layer6.shape)\n",
    "        x = layer5 # added\n",
    "        #print(x.shape)        \n",
    "        \n",
    "        \"\"\"x = torch.cat([x, layer5], dim=1)\n",
    "        x = self.conv_up5(x) # added\n",
    "        #print(x.shape)\n",
    "        #print(layer4.shape)\"\"\"\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, layer4], dim=1)\n",
    "        x = self.conv_up4(x) # added\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(layer3.shape)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        #print(x.shape)\n",
    "        #print(layer2.shape)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x = self.upsample(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.upsample(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv_original_size(x)        \n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        #return out\n",
    "        #print(input.shape)\n",
    "        #print(out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "         LeakyReLU-3         [-1, 64, 128, 128]               0\n",
      "            Conv2d-4           [-1, 64, 64, 64]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 64, 64]             128\n",
      "         LeakyReLU-6           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-7           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
      "         LeakyReLU-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10          [-1, 128, 16, 16]          73,856\n",
      "         Upsample-11          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-13          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-14          [-1, 128, 16, 16]               0\n",
      "      BatchNorm2d-15          [-1, 128, 16, 16]             256\n",
      "        LeakyReLU-16          [-1, 128, 16, 16]               0\n",
      "           Conv2d-17            [-1, 256, 8, 8]         295,168\n",
      "         Upsample-18          [-1, 256, 16, 16]               0\n",
      "      BatchNorm2d-19          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-20          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-21            [-1, 256, 8, 8]               0\n",
      "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
      "        LeakyReLU-23            [-1, 256, 8, 8]               0\n",
      "           Conv2d-24            [-1, 512, 4, 4]       1,180,160\n",
      "         Upsample-25            [-1, 512, 8, 8]               0\n",
      "      BatchNorm2d-26            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-27            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-28            [-1, 512, 4, 4]               0\n",
      "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-30            [-1, 512, 4, 4]               0\n",
      "           Conv2d-31           [-1, 1024, 2, 2]       4,719,616\n",
      "         Upsample-32           [-1, 1024, 4, 4]               0\n",
      "      BatchNorm2d-33           [-1, 1024, 4, 4]           2,048\n",
      "        LeakyReLU-34           [-1, 1024, 4, 4]               0\n",
      "        MaxPool2d-35           [-1, 1024, 2, 2]               0\n",
      "      BatchNorm2d-36           [-1, 1024, 2, 2]           2,048\n",
      "        LeakyReLU-37           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-38           [-1, 2048, 1, 1]      18,876,416\n",
      "         Upsample-39           [-1, 2048, 2, 2]               0\n",
      "         Upsample-40           [-1, 2048, 4, 4]               0\n",
      "         Upsample-41           [-1, 3072, 8, 8]               0\n",
      "      BatchNorm2d-42           [-1, 3072, 8, 8]           6,144\n",
      "        LeakyReLU-43           [-1, 3072, 8, 8]               0\n",
      "           Conv2d-44           [-1, 1024, 8, 8]      28,312,576\n",
      "      BatchNorm2d-45           [-1, 1024, 8, 8]           2,048\n",
      "        LeakyReLU-46           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-47           [-1, 1024, 8, 8]       9,438,208\n",
      "         Upsample-48         [-1, 1536, 16, 16]               0\n",
      "      BatchNorm2d-49         [-1, 1536, 16, 16]           3,072\n",
      "        LeakyReLU-50         [-1, 1536, 16, 16]               0\n",
      "           Conv2d-51          [-1, 512, 16, 16]       7,078,400\n",
      "      BatchNorm2d-52          [-1, 512, 16, 16]           1,024\n",
      "        LeakyReLU-53          [-1, 512, 16, 16]               0\n",
      "           Conv2d-54          [-1, 512, 16, 16]       2,359,808\n",
      "         Upsample-55          [-1, 768, 32, 32]               0\n",
      "      BatchNorm2d-56          [-1, 768, 32, 32]           1,536\n",
      "        LeakyReLU-57          [-1, 768, 32, 32]               0\n",
      "           Conv2d-58          [-1, 256, 32, 32]       1,769,728\n",
      "      BatchNorm2d-59          [-1, 256, 32, 32]             512\n",
      "        LeakyReLU-60          [-1, 256, 32, 32]               0\n",
      "           Conv2d-61          [-1, 256, 32, 32]         590,080\n",
      "         Upsample-62          [-1, 384, 64, 64]               0\n",
      "      BatchNorm2d-63          [-1, 384, 64, 64]             768\n",
      "        LeakyReLU-64          [-1, 384, 64, 64]               0\n",
      "           Conv2d-65          [-1, 128, 64, 64]         442,496\n",
      "      BatchNorm2d-66          [-1, 128, 64, 64]             256\n",
      "        LeakyReLU-67          [-1, 128, 64, 64]               0\n",
      "           Conv2d-68          [-1, 128, 64, 64]         147,584\n",
      "         Upsample-69        [-1, 192, 128, 128]               0\n",
      "         Upsample-70        [-1, 192, 256, 256]               0\n",
      "         Upsample-71        [-1, 192, 512, 512]               0\n",
      "         Upsample-72      [-1, 192, 1024, 1024]               0\n",
      "           Conv2d-73         [-1, 64, 512, 512]         110,656\n",
      "      BatchNorm2d-74         [-1, 64, 512, 512]             128\n",
      "        LeakyReLU-75         [-1, 64, 512, 512]               0\n",
      "           Conv2d-76         [-1, 64, 256, 256]          36,928\n",
      "           Conv2d-77          [-1, 3, 256, 256]             195\n",
      "================================================================\n",
      "Total params: 75,494,147\n",
      "Trainable params: 75,494,147\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 2594.33\n",
      "Params size (MB): 287.99\n",
      "Estimated Total Size (MB): 2883.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model = ResNetUNet(6)\n",
    "model = ResNetUNet(3)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#summary(model, input_size=(3, 224, 224))\n",
    "#print(model)\n",
    "summary(model, input_size=(inputs[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "\n",
    " \n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "Epoch 0/19\n",
      "----------\n",
      "LR 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntuos/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bce: 0.205724, dice: 0.801613, loss: 0.503668\n",
      "val: bce: 0.246981, dice: 0.786267, loss: 0.516624\n",
      "saving best model\n",
      "4m 1s\n",
      "Epoch 1/19\n",
      "----------\n",
      "LR 1\n",
      "train: bce: 0.195230, dice: 0.779837, loss: 0.487533\n",
      "val: bce: 0.210212, dice: 0.761439, loss: 0.485825\n",
      "saving best model\n",
      "4m 2s\n",
      "Epoch 2/19\n",
      "----------\n",
      "LR 1\n",
      "train: bce: 0.192577, dice: 0.776476, loss: 0.484527\n",
      "val: bce: 0.208722, dice: 0.827468, loss: 0.518095\n",
      "4m 3s\n",
      "Epoch 3/19\n",
      "----------\n",
      "LR 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "#num_class = 6\n",
    "num_class = 3\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "# Comment out to finetune further\n",
    "for l in list(model.children()):\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "#optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "#optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "optimizer_ft = optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=1)\n",
    "\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)        \n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=1/(10/len(str(batch_size))))\n",
    "        \n",
    "#model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=15)\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "#model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=int((2*train_set.count)**(1/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "\n",
    "print(pred.shape)\n",
    "print(pred.max(), pred.min())\n",
    "print(np.unique(pred))\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "#print(np.unique(np.array(target_masks_rgb[0])))\n",
    "#print(np.array((labels[0])))\n",
    "\n",
    "#target_masks_rgb = [helper.masks_to_colorimg(x) for x in np.ceil(labels.cpu().numpy()*4.0)]\n",
    "#pred_rgb = [helper.masks_to_colorimg(x) for x in np.floor(pred*4.0)]\n",
    "\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()*3.0]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred*3.0]\n",
    "\n",
    "\n",
    "\n",
    "print(labels.cpu().numpy()[0][0][0][0], pred[0][0][0][0])\n",
    "print(target_masks_rgb[0][0][0], pred_rgb[0][0][0])\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"/home/ubuntuos/pytorch-unet/pytorch_resnet18_unet_25000_trained\")\n",
    "#model = torch.load(\"/home/ubuntuos/pytorch-unet/pytorch_resnet18_unet_25000_trained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
