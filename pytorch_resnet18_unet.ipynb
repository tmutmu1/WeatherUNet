{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 256, 256, 3)\n",
      "0 255\n",
      "(2, 6, 256, 256)\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(256, 256, count=2)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "#target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask\n",
    "#helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Images...\n",
      "Appending Images...\n",
      "Input:  (100, 256, 256, 3)\n",
      "Masks:  (100, 3, 256, 256)\n",
      "Reading Images...\n",
      "Appending Images...\n",
      "Input:  (10, 256, 256, 3)\n",
      "Masks:  (10, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 100, 'val': 10}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import cv2\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.numImageInput = 3\n",
    "        self.count = count\n",
    "        #self.input_images, self.target_masks = simulation.generate_random_data(256, 256, count=count)      \n",
    "        #self.input_images, self.target_masks = self.get_images(3,3, count)\n",
    "        self.get_images(3,3, count)\n",
    "        \n",
    "        #print(self.target_masks)\n",
    "        #self.target_masks = np.reshape(self.target_masks, (count, 255, 255))\n",
    "        print(\"Input: \", self.input_images.shape)\n",
    "        print(\"Masks: \", self.target_masks.shape)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        #print(\"Image: \"+str(image.shape))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]\n",
    "\n",
    "    def get_images(self,X,Y, count):\n",
    "        count+=self.numImageInput\n",
    "        path = \"/home/ubuntuos/WeatherTileExamples/scripts/output/cropped/\" + \"(\"+str(X)+\", \" + str(Y) +\")/\"\n",
    "   \n",
    "        files= os.listdir(path)\n",
    "        images = []\n",
    "        image_output = []\n",
    "        #output = []\n",
    "       \n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith(\"(\"+str(X)+\", \"+str(Y)+\").png\"):\n",
    "                images.append(file)\n",
    "        #images = np.random.choice(np.array(images), count, replace=False)\n",
    "        #print(np.random.choice(list(enumerate(np.array(images)[:count]))))\n",
    "        \n",
    "        images.sort()\n",
    "        #rand_number = random.randint(0, len(images)-count)\n",
    "        #images = images[rand_number:rand_number+count]\n",
    "        \n",
    "        rand_int = np.random.choice(len(images)-self.numImageInput, size=count, replace=False)\n",
    "        \n",
    "        print(\"Reading Images...\")\n",
    "        #for image_path in images:\n",
    "        for i in range(len(images)):\n",
    "            if (i in rand_int or i-1 in rand_int or i-2 in rand_int or i-self.numImageInput in rand_int):\n",
    "                #input_path = os.path.join(path, image_path)\n",
    "                input_path = os.path.join(path, images[i])\n",
    "                an_image = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image_output.append(np.array(an_image))\n",
    "            else:\n",
    "                image_output.append(0)\n",
    "        output_mask = []\n",
    "        output = []\n",
    "        \n",
    "        \n",
    "        #print(rand_int)\n",
    "        print(\"Appending Images...\")\n",
    "        for i in range(count-self.numImageInput):\n",
    "            #mask_temp = np.dstack((image_output[i+3]))\n",
    "            mask_temp = [(np.round(image_output[rand_int[i]+self.numImageInput]/255*3)/3).astype(\"float16\"),\n",
    "                         (np.round(image_output[rand_int[i]+self.numImageInput]/255*3)/3).astype(\"float16\"),\n",
    "                         (np.round(image_output[rand_int[i]+self.numImageInput]/255*3)/3).astype(\"float16\")]\n",
    "    \n",
    "\n",
    "            #print(rand_int[i])\n",
    "            image_temp = np.dstack((image_output[rand_int[i]], image_output[rand_int[i]+1],image_output[rand_int[i]+2]))\n",
    "\n",
    "            #image_temp = np.array([image_output[i], image_output[i+1],image_output[i+2]])\n",
    "            output.append(image_temp)\n",
    "            output_mask.append(mask_temp)\n",
    "        self.input_images = np.array(output)\n",
    "        #self.target_masks = np.divide(np.array(output_mask), 255)\n",
    "        #self.target_masks = np.floor((np.array(output_mask)*4.0) / 255)/4\n",
    "        #self.target_masks = np.rint(np.array(output_mask)*3.0 / 255) /3\n",
    "        self.target_masks = np.array(output_mask)\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(100, transform=trans)\n",
    "#train_set = SimDataset(1000, transform=trans)\n",
    "val_set = SimDataset(10, transform=trans)\n",
    "#val_set = SimDataset(100, transform=trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "#batch_size = 25\n",
    "#batch_size = 20\n",
    "batch_size = 3\n",
    "#batch_size = 1\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 256, 256]) torch.Size([3, 3, 256, 256])\n",
      "-2.117904 0.68793046 -1.9328041 0.2722649\n",
      "0.0 0.6665 0.01354 0.0663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf7c45b5c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "#inputs = next(iter(dataloaders['train']))\n",
    "\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "base_model = models.resnet18(pretrained=False)\n",
    "    \n",
    "list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-11           [-1, 64, 64, 64]               0\n",
      "           Conv2d-12           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 64, 64]             128\n",
      "             ReLU-14           [-1, 64, 64, 64]               0\n",
      "           Conv2d-15           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 64, 64]             128\n",
      "             ReLU-17           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-18           [-1, 64, 64, 64]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
      "           Conv2d-24          [-1, 128, 32, 32]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 32, 32]             256\n",
      "             ReLU-26          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
      "             ReLU-30          [-1, 128, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-34          [-1, 128, 32, 32]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 82.01\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 127.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "#summary(base_model, input_size=(3, 224, 224))\n",
    "summary(base_model, input_size=(inputs[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import resnet18 #added\n",
    "\n",
    "\n",
    "def createUpLayer(in_channels, out_channels, kernel, padding):\n",
    "    \"\"\"return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\"\"\"\n",
    "    \"\"\"return nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "    )\"\"\"\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel, padding=padding)\n",
    "    )\n",
    "\n",
    "def createDownLayer(size): #added\n",
    "        return(nn.Sequential(\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Conv2d(size, size*2, 3, stride = 2, padding=1),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) #not in Google's model\n",
    "        ))\n",
    "        \"\"\"return(nn.Sequential(\n",
    "            resnet18.BasicBlock(size, size*2, stride = 2, downsample = nn.Sequential(\n",
    "                    nn.Conv2d(size, size*2, 3, stride = 2, padding=1),\n",
    "                    nn.BatchNorm2d(size*2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
    "                )),\n",
    "            resnet18.BasicBlock(size*2, size*2, stride = 1)))\"\"\"\n",
    "        \n",
    "def createBasicLayer(size): #added\n",
    "        return(nn.Sequential(\n",
    "            nn.Conv2d(3, size, 3, stride = 2, padding=1),\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Conv2d(size, size, 3, stride = 2, padding=1)\n",
    "        ))\n",
    "\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())       \n",
    "   \n",
    "        \n",
    "        self.layer0 = createBasicLayer(64)\n",
    "        self.layer1 = createDownLayer(64)  # size=(N, 128, x.H/8, x.W/8) # changed\n",
    "        self.layer2 = createDownLayer(128)  # size=(N, 256, x.H/16, x.W/16)  # changed      \n",
    "        self.layer3 = createDownLayer(256)  # size=(N, 512, x.H/32, x.W/32)  # changed\n",
    "        \n",
    "        self.layer4 = createDownLayer(512) # added\n",
    "        self.layer5 = createDownLayer(1024) # added\n",
    "        self.layer6 = createDownLayer(2048) # added\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        \n",
    "        self.conv_up5 = createUpLayer(4096 + 2048, 2048, 3, 1) # added\n",
    "        self.conv_up4 = createUpLayer(2048 + 1024, 1024, 3, 1) # added\n",
    "        \n",
    "        self.conv_up3 = createUpLayer(1024 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = createUpLayer(512 + 256, 256, 3, 1)\n",
    "        self.conv_up1 = createUpLayer(256 + 128, 128, 3, 1)\n",
    "        self.conv_up0 = createUpLayer(128, 64, 3, 1)\n",
    "        \n",
    "        \"\"\"self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\"\"\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\"x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\"\"\"\n",
    "\n",
    "        layer0 = self.layer0(input)    \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer5 = self.layer5(layer4) #added        \n",
    "        \n",
    "        layer6 = self.layer6(layer5) #added        \n",
    "        #print(layer6.shape)\n",
    "        x = layer6 # added\n",
    "        #print(x.shape)\n",
    "\n",
    "        x = torch.cat([x, layer5], dim=1)\n",
    "        x = self.conv_up5(x) # added\n",
    "        #print(x.shape)\n",
    "        #print(layer4.shape)\n",
    "        \n",
    "        x = torch.cat([x, layer4], dim=1)\n",
    "        x = self.conv_up4(x) # added\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(layer3.shape)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        #print(x.shape)\n",
    "        #print(layer2.shape)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        \n",
    "        \"\"\"x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)\"\"\"\n",
    "\n",
    "        #return out\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "         LeakyReLU-3         [-1, 64, 128, 128]               0\n",
      "            Conv2d-4           [-1, 64, 64, 64]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 64, 64]             128\n",
      "         LeakyReLU-6           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-7           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
      "         LeakyReLU-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10          [-1, 128, 16, 16]          73,856\n",
      "         Upsample-11          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-13          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-14          [-1, 128, 16, 16]               0\n",
      "      BatchNorm2d-15          [-1, 128, 16, 16]             256\n",
      "        LeakyReLU-16          [-1, 128, 16, 16]               0\n",
      "           Conv2d-17            [-1, 256, 8, 8]         295,168\n",
      "         Upsample-18          [-1, 256, 16, 16]               0\n",
      "      BatchNorm2d-19          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-20          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-21            [-1, 256, 8, 8]               0\n",
      "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
      "        LeakyReLU-23            [-1, 256, 8, 8]               0\n",
      "           Conv2d-24            [-1, 512, 4, 4]       1,180,160\n",
      "         Upsample-25            [-1, 512, 8, 8]               0\n",
      "      BatchNorm2d-26            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-27            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-28            [-1, 512, 4, 4]               0\n",
      "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-30            [-1, 512, 4, 4]               0\n",
      "           Conv2d-31           [-1, 1024, 2, 2]       4,719,616\n",
      "         Upsample-32           [-1, 1024, 4, 4]               0\n",
      "      BatchNorm2d-33           [-1, 1024, 4, 4]           2,048\n",
      "        LeakyReLU-34           [-1, 1024, 4, 4]               0\n",
      "        MaxPool2d-35           [-1, 1024, 2, 2]               0\n",
      "      BatchNorm2d-36           [-1, 1024, 2, 2]           2,048\n",
      "        LeakyReLU-37           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-38           [-1, 2048, 1, 1]      18,876,416\n",
      "         Upsample-39           [-1, 2048, 2, 2]               0\n",
      "      BatchNorm2d-40           [-1, 2048, 2, 2]           4,096\n",
      "        LeakyReLU-41           [-1, 2048, 2, 2]               0\n",
      "        MaxPool2d-42           [-1, 2048, 1, 1]               0\n",
      "      BatchNorm2d-43           [-1, 2048, 1, 1]           4,096\n",
      "        LeakyReLU-44           [-1, 2048, 1, 1]               0\n",
      "           Conv2d-45           [-1, 4096, 1, 1]      75,501,568\n",
      "         Upsample-46           [-1, 4096, 2, 2]               0\n",
      "         Upsample-47           [-1, 6144, 4, 4]               0\n",
      "      BatchNorm2d-48           [-1, 6144, 4, 4]          12,288\n",
      "        LeakyReLU-49           [-1, 6144, 4, 4]               0\n",
      "           Conv2d-50           [-1, 2048, 4, 4]     113,248,256\n",
      "      BatchNorm2d-51           [-1, 2048, 4, 4]           4,096\n",
      "        LeakyReLU-52           [-1, 2048, 4, 4]               0\n",
      "           Conv2d-53           [-1, 2048, 4, 4]      37,750,784\n",
      "         Upsample-54           [-1, 3072, 8, 8]               0\n",
      "      BatchNorm2d-55           [-1, 3072, 8, 8]           6,144\n",
      "        LeakyReLU-56           [-1, 3072, 8, 8]               0\n",
      "           Conv2d-57           [-1, 1024, 8, 8]      28,312,576\n",
      "      BatchNorm2d-58           [-1, 1024, 8, 8]           2,048\n",
      "        LeakyReLU-59           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-60           [-1, 1024, 8, 8]       9,438,208\n",
      "         Upsample-61         [-1, 1536, 16, 16]               0\n",
      "      BatchNorm2d-62         [-1, 1536, 16, 16]           3,072\n",
      "        LeakyReLU-63         [-1, 1536, 16, 16]               0\n",
      "           Conv2d-64          [-1, 512, 16, 16]       7,078,400\n",
      "      BatchNorm2d-65          [-1, 512, 16, 16]           1,024\n",
      "        LeakyReLU-66          [-1, 512, 16, 16]               0\n",
      "           Conv2d-67          [-1, 512, 16, 16]       2,359,808\n",
      "         Upsample-68          [-1, 768, 32, 32]               0\n",
      "      BatchNorm2d-69          [-1, 768, 32, 32]           1,536\n",
      "        LeakyReLU-70          [-1, 768, 32, 32]               0\n",
      "           Conv2d-71          [-1, 256, 32, 32]       1,769,728\n",
      "      BatchNorm2d-72          [-1, 256, 32, 32]             512\n",
      "        LeakyReLU-73          [-1, 256, 32, 32]               0\n",
      "           Conv2d-74          [-1, 256, 32, 32]         590,080\n",
      "         Upsample-75          [-1, 384, 64, 64]               0\n",
      "      BatchNorm2d-76          [-1, 384, 64, 64]             768\n",
      "        LeakyReLU-77          [-1, 384, 64, 64]               0\n",
      "           Conv2d-78          [-1, 128, 64, 64]         442,496\n",
      "      BatchNorm2d-79          [-1, 128, 64, 64]             256\n",
      "        LeakyReLU-80          [-1, 128, 64, 64]               0\n",
      "           Conv2d-81          [-1, 128, 64, 64]         147,584\n",
      "================================================================\n",
      "Total params: 301,871,424\n",
      "Trainable params: 301,871,424\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 140.16\n",
      "Params size (MB): 1151.55\n",
      "Estimated Total Size (MB): 1292.45\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model = ResNetUNet(6)\n",
    "model = ResNetUNet(3)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#summary(model, input_size=(3, 224, 224))\n",
    "#print(model)\n",
    "summary(model, input_size=(inputs[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "\n",
    " \n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "Epoch 0/19\n",
      "----------\n",
      "LR 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntuos/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([3, 3, 256, 256])) must be the same as input size (torch.Size([3, 192, 64, 64]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cbdf70b35bd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=15)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m#model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=int((2*train_set.count)**(1/3)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1f7ce0ca6672>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1f7ce0ca6672>\u001b[0m in \u001b[0;36mcalc_loss\u001b[0;34m(pred, target, metrics, bce_weight)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([3, 3, 256, 256])) must be the same as input size (torch.Size([3, 192, 64, 64]))"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "#num_class = 6\n",
    "num_class = 3\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "# Comment out to finetune further\n",
    "for l in list(model.children()):\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "#optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "#optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "optimizer_ft = optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=1)\n",
    "\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)        \n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=1/(10/len(str(batch_size))))\n",
    "        \n",
    "#model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=15)\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "#model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=int((2*train_set.count)**(1/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "\n",
    "print(pred.shape)\n",
    "print(pred.max(), pred.min())\n",
    "print(np.unique(pred))\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "#print(np.unique(np.array(target_masks_rgb[0])))\n",
    "#print(np.array((labels[0])))\n",
    "\n",
    "#target_masks_rgb = [helper.masks_to_colorimg(x) for x in np.ceil(labels.cpu().numpy()*4.0)]\n",
    "#pred_rgb = [helper.masks_to_colorimg(x) for x in np.floor(pred*4.0)]\n",
    "\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()*3.0]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred*3.0]\n",
    "\n",
    "\n",
    "\n",
    "print(labels.cpu().numpy()[0][0][0][0], pred[0][0][0][0])\n",
    "print(target_masks_rgb[0][0][0], pred_rgb[0][0][0])\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"/home/ubuntuos/pytorch-unet/pytorch_resnet18_unet_25000_trained\")\n",
    "#model = torch.load(\"/home/ubuntuos/pytorch-unet/pytorch_resnet18_unet_25000_trained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
