{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(256, 256, count=2)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "#target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask\n",
    "#helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import cv2\n",
    "import datetime\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.numImageInput = 5\n",
    "        self.count = count\n",
    "        #self.input_images, self.target_masks = simulation.generate_random_data(256, 256, count=count)      \n",
    "        #self.input_images, self.target_masks = self.get_images(3,3, count)\n",
    "        self.get_images(3,3, count)\n",
    "        \n",
    "        #print(self.target_masks)\n",
    "        #self.target_masks = np.reshape(self.target_masks, (count, 255, 255))\n",
    "        print(\"Input: \", self.input_images.shape)\n",
    "        print(\"Masks: \", self.target_masks.shape)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        #print(\"Image: \"+str(image.shape))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]\n",
    "\n",
    "    def getNextImageName(self, path):\n",
    "        dateStartIndex = path.find(\"_\")+1\n",
    "        year = path[dateStartIndex:dateStartIndex+4]\n",
    "        month = path[dateStartIndex+4:dateStartIndex+6]\n",
    "        day = path[dateStartIndex+6:dateStartIndex+8]\n",
    "\n",
    "        timeStartIndex = path.find(\"-\")+1\n",
    "        hour=path[timeStartIndex:timeStartIndex+2]\n",
    "        minute=path[timeStartIndex+2:timeStartIndex+4]\n",
    "\n",
    "        inputImageTime = datetime.datetime(int(year), int(month), int(day), int(hour), int(minute))\n",
    "        timeInterval = datetime.timedelta(minutes=2)\n",
    "        outputImageTime = inputImageTime+timeInterval\n",
    "        outputImageTime.strftime(\"%Y%m%d-%H%M00\")\n",
    "        outputPath = \"CONUS_\" + str(outputImageTime.strftime(\"%Y%m%d-%H%M\")) +path[timeStartIndex+4:]\n",
    "        return(outputPath)\n",
    "\n",
    "    def checkImages(self, path, images, imageIndex):\n",
    "        if not (os.path.exists(os.path.join(path, self.getNextImageName(images[imageIndex])))):\n",
    "            print(os.path.join(path, self.getNextImageName(images[imageIndex])))\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def get_images(self, X,Y, count):\n",
    "        count+=self.numImageInput\n",
    "        path = \"/home/ubuntuos/WeatherUNet/WeatherTiles/scripts/output/cropped/\" + \"(\"+str(X)+\", \" + str(Y) +\")/\"\n",
    "   \n",
    "        files= os.listdir(path)\n",
    "        images = []\n",
    "        image_output = []\n",
    "        #output = []\n",
    "       \n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith(\"(\"+str(X)+\", \"+str(Y)+\").png\"):\n",
    "                images.append(file)\n",
    "        \n",
    "        images.sort()\n",
    "\n",
    "        rand_int = np.random.choice(len(images)-self.numImageInput, size=count-self.numImageInput, replace=False)\n",
    "        \n",
    "        print(\"Reading Images...\")\n",
    "        imageIndex=0\n",
    "        while len(image_output) < (count-self.numImageInput)*(self.numImageInput+1):\n",
    "            #if (i in rand_int or i-1 in rand_int or i-2 in rand_int or i-self.numImageInput in rand_int):\n",
    "            if (imageIndex in rand_int or imageIndex-1 in rand_int or imageIndex-2 in rand_int or imageIndex-3 in rand_int or imageIndex-4 in rand_int or imageIndex-5 in rand_int):\n",
    "                if self.checkImages(path, images, imageIndex):\n",
    "                    #input_path = os.path.join(path, image_path)\n",
    "                    input_path = os.path.join(path, images[imageIndex])\n",
    "                    an_image = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    image_output.append(np.array(an_image))\n",
    "            imageIndex+=1\n",
    "            if imageIndex > count-self.numImageInput*(self.numImageInput+1):\n",
    "                rand_int = np.random.choice(len(images)-self.numImageInput, size=count-self.numImageInput, replace=False)\n",
    "                imageIndex=0\n",
    "\n",
    "            \n",
    "        output_mask = []\n",
    "        output = []\n",
    "        \n",
    "        #print(rand_int)\n",
    "        print(len(image_output))\n",
    "        print(\"Appending Images...\")\n",
    "        for i in range(count-self.numImageInput):\n",
    "            #mask_temp = np.dstack((image_output[i+3]))\n",
    "            \"\"\"mask_temp = [(np.round(image_output[rand_int[i]+self.numImageInput-2]/255*3)/3).astype(\"float16\"),\n",
    "                         (np.round(image_output[rand_int[i]+self.numImageInput-1]/255*3)/3).astype(\"float16\"),\n",
    "                         (np.round(image_output[rand_int[i]+self.numImageInput]/255*3)/3).astype(\"float16\")]\"\"\"\n",
    "            mask_temp = [(np.round(image_output[i+self.numImageInput-2]/255*3)/3).astype(\"float16\"),\n",
    "                         (np.round(image_output[i+self.numImageInput-1]/255*3)/3).astype(\"float16\"),\n",
    "                         (np.round(image_output[i+self.numImageInput]/255*3)/3).astype(\"float16\")]\n",
    "    \n",
    "\n",
    "            #print(rand_int[i])\n",
    "            image_temp = np.dstack((image_output[i], image_output[i+1],image_output[i+2]))\n",
    "\n",
    "            #image_temp = np.array([image_output[i], image_output[i+1],image_output[i+2]])\n",
    "            output.append(image_temp)\n",
    "            output_mask.append(mask_temp)\n",
    "        self.input_images = np.array(output)\n",
    "        #self.target_masks = np.divide(np.array(output_mask), 255)\n",
    "        #self.target_masks = np.floor((np.array(output_mask)*4.0) / 255)/4\n",
    "        #self.target_masks = np.rint(np.array(output_mask)*3.0 / 255) /3\n",
    "        self.target_masks = np.array(output_mask)\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(250, transform=trans)\n",
    "#train_set = SimDataset(1000, transform=trans)\n",
    "val_set = SimDataset(25, transform=trans)\n",
    "#val_set = SimDataset(100, transform=trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "#batch_size = 25\n",
    "#batch_size = 20\n",
    "batch_size = 3\n",
    "#batch_size = 1\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "#inputs = next(iter(dataloaders['train']))\n",
    "\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "base_model = models.resnet18(pretrained=False)\n",
    "    \n",
    "list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "#summary(base_model, input_size=(3, 224, 224))\n",
    "summary(base_model, input_size=(inputs[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import resnet18 #added\n",
    "\n",
    "\n",
    "def createUpLayer(in_channels, out_channels, kernel, padding):\n",
    "    \"\"\"return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\"\"\"\n",
    "    \"\"\"return nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "    )\"\"\"\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel, padding=padding)\n",
    "    )\n",
    "\n",
    "def createDownLayer(size): #added\n",
    "        return(nn.Sequential(\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Conv2d(size, size*2, 3, stride = 2, padding=1),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) #not in Google's model\n",
    "        ))\n",
    "        \"\"\"return(nn.Sequential(\n",
    "            resnet18.BasicBlock(size, size*2, stride = 2, downsample = nn.Sequential(\n",
    "                    nn.Conv2d(size, size*2, 3, stride = 2, padding=1),\n",
    "                    nn.BatchNorm2d(size*2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
    "                )),\n",
    "            resnet18.BasicBlock(size*2, size*2, stride = 1)))\"\"\"\n",
    "        \n",
    "def createBasicLayer(inputSize, size): #added\n",
    "        return(nn.Sequential(\n",
    "            nn.Conv2d(inputSize, size, 3, stride = 2, padding=1),\n",
    "            nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Conv2d(size, size, 3, stride = 2, padding=1)\n",
    "        ))\n",
    "\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())       \n",
    "   \n",
    "        \n",
    "        self.layer0 = createBasicLayer(3, 64)\n",
    "        self.layer1 = createDownLayer(64)  # size=(N, 128, x.H/8, x.W/8) # changed\n",
    "        self.layer2 = createDownLayer(128)  # size=(N, 256, x.H/16, x.W/16)  # changed      \n",
    "        self.layer3 = createDownLayer(256)  # size=(N, 512, x.H/32, x.W/32)  # changed\n",
    "        \n",
    "        self.layer4 = createDownLayer(512) # added\n",
    "        self.layer5 = createDownLayer(1024) # added\n",
    "        #self.layer6 = createDownLayer(2048) # added\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        \n",
    "        #self.conv_up5 = createUpLayer(4096 + 2048, 2048, 3, 1) # added\n",
    "        self.conv_up4 = createUpLayer(2048 + 1024, 1024, 3, 1) # added\n",
    "        \n",
    "        self.conv_up3 = createUpLayer(1024 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = createUpLayer(512 + 256, 256, 3, 1)\n",
    "        self.conv_up1 = createUpLayer(256 + 128, 128, 3, 1)\n",
    "        self.conv_up0 = createUpLayer(128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_original_size = createBasicLayer(192, 64)\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\"\"\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        layer0 = self.layer0(input)    \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer5 = self.layer5(layer4) #added        \n",
    "        #layer6 = self.layer6(layer5) #added        \n",
    "\n",
    "        #print(layer6.shape)\n",
    "        x = layer5 # added\n",
    "        #print(x.shape)        \n",
    "        \n",
    "        \"\"\"x = torch.cat([x, layer5], dim=1)\n",
    "        x = self.conv_up5(x) # added\n",
    "        #print(x.shape)\n",
    "        #print(layer4.shape)\"\"\"\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, layer4], dim=1)\n",
    "        x = self.conv_up4(x) # added\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(layer3.shape)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        #print(x.shape)\n",
    "        #print(layer2.shape)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x = self.upsample(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.upsample(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv_original_size(x)        \n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        #return out\n",
    "        #print(input.shape)\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model = ResNetUNet(6)\n",
    "model = ResNetUNet(3)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#summary(model, input_size=(3, 224, 224))\n",
    "#print(model)\n",
    "summary(model, input_size=(inputs[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "\n",
    " \n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "#num_class = 6\n",
    "num_class = 3\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "# Comment out to finetune further\n",
    "for l in list(model.children()):\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "#optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "#optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "optimizer_ft = optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=1)\n",
    "\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)        \n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=1/(10/len(str(batch_size))))\n",
    "        \n",
    "#model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=15)\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "#model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=int((2*train_set.count)**(1/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "\n",
    "print(pred.shape)\n",
    "print(pred.max(), pred.min())\n",
    "print(np.unique(pred))\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "#print(np.unique(np.array(target_masks_rgb[0])))\n",
    "#print(np.array((labels[0])))\n",
    "\n",
    "#target_masks_rgb = [helper.masks_to_colorimg(x) for x in np.ceil(labels.cpu().numpy()*4.0)]\n",
    "#pred_rgb = [helper.masks_to_colorimg(x) for x in np.floor(pred*4.0)]\n",
    "\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()*3.0]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred*3.0]\n",
    "\n",
    "\n",
    "\n",
    "print(labels.cpu().numpy()[0][0][0][0], pred[0][0][0][0])\n",
    "print(target_masks_rgb[0][0][0], pred_rgb[0][0][0])\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"/home/ubuntuos/pytorch-unet/pytorch_resnet18_unet_25000_trained\")\n",
    "#model = torch.load(\"/home/ubuntuos/pytorch-unet/pytorch_resnet18_unet_25000_trained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
